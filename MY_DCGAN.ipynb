{"cells":[{"cell_type":"markdown","metadata":{"id":"8yMdb4KuRYcC"},"source":["# **硬體資源確認:**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1640632818338,"user":{"displayName":"SK","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7--4P44AfAvjw0rUOGVSabQNlfWVEWivQJE9UZA=s64","userId":"06193962436829705248"},"user_tz":-480},"id":"JOLB0DExRY-b","outputId":"75bc06a8-cdd7-4ce6-8849-f988b77abb5f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Dec 27 19:20:17 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Your runtime has 27.3 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eyxTWnTMcUK_"},"outputs":[],"source":["import tensorflow as tf\n","import os\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers, models\n","from tensorflow.keras import optimizers\n","from tqdm import tqdm\n","import time\n","import matplotlib.pyplot as plt\n","import gdown\n","import zipfile"]},{"cell_type":"markdown","metadata":{"id":"O8C7ch8Fhr2s"},"source":["# **Preprocessing:**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75666,"status":"ok","timestamp":1640674318342,"user":{"displayName":"SK","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7--4P44AfAvjw0rUOGVSabQNlfWVEWivQJE9UZA=s64","userId":"06193962436829705248"},"user_tz":-480},"id":"wshQhTNbp4mV","outputId":"e4329573-d2dc-4e0e-c2d3-7fdbf93406e5"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/u/0/uc?id=1GTiaKUgKWzNAWzQ00sYvmb8GELKk8bsN&export=download\n","To: /content/dataset/data.zip\n","100%|██████████| 2.11G/2.11G [00:37<00:00, 57.0MB/s]\n"]}],"source":["# 直接下載celeba資料集使用(Google colab)\n","if not os.path.isdir(\"/content/dataset\"):\n","  os.makedirs(\"/content/dataset\")                        # 不要載到drive 直接放雲端本機\n","\n","# url = \"https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\"  #Celeba\n","url = \"https://drive.google.com/u/0/uc?id=1GTiaKUgKWzNAWzQ00sYvmb8GELKk8bsN&export=download\" #FFHQ\n","output = \"dataset/data.zip\"\n","gdown.download(url, output, quiet=False)\n","\n","with zipfile.ZipFile(\"dataset/data.zip\", \"r\") as zipobj:\n","    zipobj.extractall(\"dataset\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eMl-9th2Xd4Z"},"outputs":[],"source":["# 刪除塞不滿的batch, batch_size (FFHQ)\n","path = \"/content/dataset/thumbnails128x128\"\n","for i in range(112):\n","  fname = \"{0:05d}.png\".format(i + 1)\n","  os.remove(os.path.join(path, fname))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4276,"status":"ok","timestamp":1640674322607,"user":{"displayName":"SK","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7--4P44AfAvjw0rUOGVSabQNlfWVEWivQJE9UZA=s64","userId":"06193962436829705248"},"user_tz":-480},"id":"hfXt1UIadZR-","outputId":"dd83b629-bfd8-4dec-dac0-a8890ec61668"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 69888 files belonging to 1 classes.\n"]}],"source":["# 資料集預處理\n","# PATH = \"/content/drive/MyDrive/Colab Notebooks/celeba\" # for test\n","PATH = \"/content/dataset\" # for train\n","dataset = keras.preprocessing.image_dataset_from_directory(\n","    PATH, label_mode=None, color_mode='rgb', image_size=(128, 128), batch_size=256, shuffle=True\n",")\n","\n","# dataset = dataset.batch(1, drop_remainder=True)\n","dataset = dataset.map(lambda x: x / 255.0)       # ※normalize [0,1]\n","dataset = dataset.map(lambda x: (x - 127.5)/ 127.5)  # ※normalize [-1,1]\n","\n","# 預先讀取訓練資料，提升效能\n","dataset = dataset.prefetch(buffer_size=256)"]},{"cell_type":"markdown","metadata":{"id":"NonhvIsKdgPa"},"source":["# **Generator:**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":634,"status":"ok","timestamp":1642138328814,"user":{"displayName":"SK","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7--4P44AfAvjw0rUOGVSabQNlfWVEWivQJE9UZA=s64","userId":"06193962436829705248"},"user_tz":-480},"id":"z_3efW9J8kVR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c7ad0cdb-126c-46a1-e351-957e0d7ec73f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"Generator\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," G_input (InputLayer)        [(None, 128)]             0         \n","                                                                 \n"," G1 (Dense)                  (None, 65536)             8388608   \n","                                                                 \n"," G_reshape (Reshape)         (None, 8, 8, 1024)        0         \n","                                                                 \n"," G1_Lrelu (LeakyReLU)        (None, 8, 8, 1024)        0         \n","                                                                 \n"," G2 (Conv2DTranspose)        (None, 16, 16, 1024)      16777216  \n","                                                                 \n"," G2_bn (BatchNormalization)  (None, 16, 16, 1024)      4096      \n","                                                                 \n"," G2_Lrelu (LeakyReLU)        (None, 16, 16, 1024)      0         \n","                                                                 \n"," conv2d_transpose (Conv2DTra  (None, 32, 32, 512)      8388608   \n"," nspose)                                                         \n","                                                                 \n"," batch_normalization (BatchN  (None, 32, 32, 512)      2048      \n"," ormalization)                                                   \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 32, 32, 512)       0         \n","                                                                 \n"," conv2d_transpose_1 (Conv2DT  (None, 64, 64, 256)      2097152   \n"," ranspose)                                                       \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 64, 64, 256)      1024      \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 64, 64, 256)       0         \n","                                                                 \n"," G5 (Conv2DTranspose)        (None, 128, 128, 128)     524288    \n","                                                                 \n"," G5_bn (BatchNormalization)  (None, 128, 128, 128)     512       \n","                                                                 \n"," G5_Lrelu (LeakyReLU)        (None, 128, 128, 128)     0         \n","                                                                 \n"," G6 (Conv2DTranspose)        (None, 128, 128, 64)      131072    \n","                                                                 \n"," G6_bn (BatchNormalization)  (None, 128, 128, 64)      256       \n","                                                                 \n"," G6_Lrelu (LeakyReLU)        (None, 128, 128, 64)      0         \n","                                                                 \n"," G7 (Conv2DTranspose)        (None, 256, 256, 3)       3072      \n","                                                                 \n"," G_final (Activation)        (None, 256, 256, 3)       0         \n","                                                                 \n","=================================================================\n","Total params: 36,317,952\n","Trainable params: 36,313,984\n","Non-trainable params: 3,968\n","_________________________________________________________________\n"]}],"source":["# 建構生成器\n","def build_generator(latent_dim=128):\n","    # 輸入潛在空間中向量\n","    vector_input = layers.Input(shape=(latent_dim,), name='G_input')\n","\n","    x = layers.Dense(1024 * 8 * 8, use_bias=False, name='G1')(vector_input)\n","    # x = layers.BatchNormalization(epsilon=0.001, name='G1_bn')(x)           # Reshape no BN !\n","    # (None, 1024)\n","    x = layers.Reshape((8, 8, 1024), name='G_reshape')(x)\n","    x = layers.LeakyReLU(alpha=0.2, name='G1_Lrelu')(x)\n","    # (None, 1, 1, 1024)\n","\n","    x = layers.Conv2DTranspose(1024, kernel_size=(4, 4),  strides=(2, 2), padding='same', use_bias=False, name='G2')(x)\n","    x = layers.BatchNormalization(epsilon=0.001, name='G2_bn')(x)\n","    x = layers.LeakyReLU(alpha=0.2, name='G2_Lrelu')(x)\n","    # (None, 4, 4, 1024)\n","\n","    '''\n","    ......\n","    '''\n","    x = layers.Conv2DTranspose(512, kernel_size=4,  strides=2, padding='same', use_bias=False)(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.LeakyReLU(alpha=0.2)(x)\n","    # (None, 16, 16, 512)\n","\n","    x = layers.Conv2DTranspose(256, kernel_size=4,  strides=2, padding='same', use_bias=False)(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.LeakyReLU(alpha=0.2)(x)\n","    # (None, 32, 32, 256) \n","\n","    x = layers.Conv2DTranspose(128, kernel_size=(4, 4),  strides=(2, 2), padding='same', use_bias=False, name='G5')(x)\n","    x = layers.BatchNormalization(epsilon=0.001, name='G5_bn')(x)\n","    x = layers.LeakyReLU(alpha=0.2, name='G5_Lrelu')(x)\n","    # (None, 32, 32, 128)\n","\n","    x = layers.Conv2DTranspose(64, kernel_size=(4, 4),  strides=(1, 1), padding='same', use_bias=False, name='G6')(x)\n","    x = layers.BatchNormalization(epsilon=0.001, name='G6_bn')(x)\n","    x = layers.LeakyReLU(alpha=0.2, name='G6_Lrelu')(x)\n","    # (None, 64, 64, 64)\n","\n","    x = layers.Conv2DTranspose(3, kernel_size=(4, 4),  strides=(2, 2), padding='same', use_bias=False, name='G7')(x)\n","    img = layers.Activation('tanh', name='G_final')(x)\n","    # (None, 128, 128, 3) \n","    generator = models.Model(vector_input, img, name='Generator')\n","\n","    generator.summary()\n","    return generator\n","\n","G = build_generator(latent_dim=128)"]},{"cell_type":"markdown","metadata":{"id":"khcdwLpR-S-g"},"source":["### 1024 128x128x3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p4A9e0Sqdc0r"},"outputs":[],"source":["# # 建構生成器\n","# def build_generator(latent_dim=128):\n","#     # 輸入潛在空間中向量\n","#     vector_input = layers.Input(shape=(latent_dim,), name='G_input')\n","\n","#     x = layers.Dense(1024 * 8 * 8, use_bias=False, name='G_1')(vector_input)\n","#     x = layers.ReLU(name='G_relu1')(x)\n","#     # (None, 32768)\n","#     x = layers.Reshape((8, 8, 1024), name='G_reshape')(x)\n","    \n","#     # (None, 8, 8, 512)\n","#     x = layers.Conv2DTranspose(512, kernel_size=(4, 4),  strides=(1, 1), padding='same', use_bias=False, name='G_2')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='G_bn2')(x)\n","#     x = layers.ReLU(name='G_relu2')(x) \n","#     # -------------------------\n","#     # transposedConv 棋盤偽影\n","#     # kernel_size & strides\n","#     # -------------------------\n","#     x = layers.Conv2DTranspose(256, kernel_size=(4, 4),  strides=(2, 2), padding='same', use_bias=False, name='G_3')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='G_bn3')(x)\n","#     x = layers.ReLU(name='G_relu3')(x)        # LeakyReLU(inplace=True)\n","#     # ReLU in G\n","#     # (None, 16, 16, 256) \n","\n","#     x = layers.Conv2DTranspose(128, kernel_size=(4, 4),  strides=(2, 2), padding='same', use_bias=False, name='G_4')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='G_bn4')(x)\n","#     x = layers.ReLU(name='G_relu4')(x)\n","#     # (None, 32, 32, 128)\n","\n","#     x = layers.Conv2DTranspose(64, kernel_size=(4, 4),  strides=(2, 2), padding='same', use_bias=False, name='G_5')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='G_bn5')(x)\n","#     x = layers.ReLU(name='G_relu5')(x)\n","#     # (None, 64, 64, 64)\n","\n","#     x = layers.Conv2DTranspose(3, kernel_size=(4, 4),  strides=(2, 2), padding='same', use_bias=False, name='G_6')(x)\n","#     img = layers.Activation('tanh', name='G_final')(x)      # Wyh TANH ?????\n","#     # 因輸入向量來自常態分布(高斯)\n","#     # (None, 64, 64, 3) \n","#     generator = models.Model(vector_input, img, name='Generator')\n","\n","#     generator.summary()\n","#     return generator\n","\n","# G = build_generator(latent_dim=128)"]},{"cell_type":"markdown","metadata":{"id":"gC-fLmKl-d2R"},"source":["512 64x64x3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BSeRI20qCvWF"},"outputs":[],"source":["# # 建構生成器\n","# def build_generator(latent_dim=128):\n","#     # 輸入潛在空間中向量\n","#     vector_input = layers.Input(shape=(latent_dim,), name='G_input')\n","#     # -------------------------\n","#     #    use_bias=False\n","#     #  通過禁用bias加速訓練\n","#     #因為輸出normalize後bias可忽略\n","#     # -------------------------\n","#     x = layers.Dense(512 * 8 * 8, use_bias=False, name='G_1')(vector_input)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='G_bn1')(x)\n","#     x = layers.ReLU(name='G_relu1')(x)\n","#     # (None, 32768)\n","#     x = layers.Reshape((8, 8, 512), name='G_reshape')(x)\n","#     # (None, 8, 8, 512)\n","\n","#     # -------------------------\n","#     # transposedConv 棋盤偽影\n","#     # kernel_size & strides\n","#     # -------------------------\n","#     x = layers.Conv2DTranspose(256, kernel_size=(4, 4),  strides=(2, 2), padding='same', use_bias=False, name='G_2')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='G_bn2')(x)\n","#     x = layers.ReLU(name='G_relu2')(x)        # LeakyReLU(inplace=True)\n","#     # ReLU in G\n","#     # (None, 16, 16, 256) \n","\n","#     x = layers.Conv2DTranspose(128, kernel_size=(4, 4),  strides=(2, 2), padding='same', use_bias=False, name='G_3')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='G_bn3')(x)\n","#     x = layers.ReLU(name='G_relu3')(x)\n","#     # (None, 32, 32, 128)\n","\n","#     x = layers.Conv2DTranspose(64, kernel_size=(4, 4),  strides=(2, 2), padding='same', use_bias=False, name='G_4')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='G_bn4')(x)\n","#     x = layers.ReLU(name='G_relu4')(x)\n","#     # (None, 64, 64, 64)\n","\n","#     x = layers.Conv2DTranspose(3, kernel_size=(4, 4),  strides=(1, 1), padding='same', use_bias=False, name='G_5')(x) # 測試\n","#     # x = layers.Conv2D(3, kernel_size=(5, 5), padding='same', use_bias=False, name='G_5')(x)\n","#     img = layers.Activation('tanh', name='G_final')(x)      # Wyh TANH ?????\n","#     # 因輸入向量來自常態分布(高斯)\n","#     # (None, 64, 64, 3) \n","#     generator = models.Model(vector_input, img, name='Generator')\n","\n","#     generator.summary()\n","#     return generator\n","\n","# G = build_generator(latent_dim=128)"]},{"cell_type":"markdown","metadata":{"id":"vQtuDDvOdub1"},"source":["# **Discriminator:**"]},{"cell_type":"markdown","metadata":{"id":"wjP_PdQI6PtS"},"source":["\n","\n","```\n","# All Conv block with dropout\n","```\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aSXr5JV4dqLz"},"outputs":[],"source":["# 建構鑑別器 (WGAN)\n","def build_discriminator(img_shape):  \n","    input_img = layers.Input(shape=img_shape, name='D_input')\n","\n","    x = layers.Conv2D(64, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D1')(input_img)\n","    x = layers.BatchNormalization(epsilon=0.001, name='D1_bn')(x)\n","    x = layers.LeakyReLU(alpha=0.2, name='D1_Lrelu')(x)\n","    x = layers.Dropout(0.3, name='D1_drop')(x)\n","    # (None, 64, 64, 64)\n","\n","    x = layers.Conv2D(128, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D2')(x)\n","    x = layers.BatchNormalization(epsilon=0.001, name='D2_bn')(x)\n","    x = layers.LeakyReLU(alpha=0.2, name='D2_Lrelu')(x)\n","    x = layers.Dropout(0.3, name='D2_drop')(x)\n","    # (None, 32, 32, 128)\n","\n","    x = layers.Conv2D(256, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D3')(x)\n","    x = layers.BatchNormalization(epsilon=0.001, name='D3_bn')(x)\n","    x = layers.LeakyReLU(alpha=0.2, name='D3_Lrelu')(x)\n","    x = layers.Dropout(0.3, name='D3_drop')(x)\n","    # (None, 16, 16, 256)\n","\n","    x = layers.Conv2D(512, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D4')(x)\n","    x = layers.BatchNormalization(epsilon=0.001, name='D4_bn')(x)\n","    x = layers.LeakyReLU(alpha=0.2, name='D4_Lrelu')(x)\n","    x = layers.Dropout(0.3, name='D4_drop')(x)\n","    # (None, 8, 8, 512)\n","\n","    x = layers.Conv2D(1024, kernel_size=(4, 4), strides=(1, 1), padding='same', use_bias=False, name='D5')(x)\n","    x = layers.BatchNormalization(epsilon=0.001, name='D5_bn')(x)\n","    x = layers.LeakyReLU(alpha=0.2, name='D5_Lrelu')(x)\n","    x = layers.Dropout(0.3, name='D5_drop')(x)\n","    # (None, 4, 4, 1024)\n","\n","    x = layers.Flatten(name='D_flat')(x)\n","    # (None, 16384)\n","\n","    out = layers.Dense(1, use_bias=False, name='D_5')(x)\n","    # out = layers.Activation('sigmoid', name='D_final')(x)           # WGAN不使用sigmoid作為D輸出\n","    # (None, 1)                                  # 此時輸出不再為可能為真的\"機率\"而是為真的\"程度\" \n","    discriminator = models.Model(input_img, out, name='Discriminator')\n","\n","    discriminator.summary()\n","    return discriminator\n","\n","# D = build_discriminator((128, 128, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e40FNj8ME3ut"},"outputs":[],"source":["# # 建構鑑別器\n","# def build_discriminator(img_shape):  \n","#     input_img = layers.Input(shape=img_shape, name='D_input')\n","\n","#     x = layers.Conv2D(64, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D1')(input_img)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='D1_bn')(x)\n","#     x = layers.LeakyReLU(alpha=0.2, name='D1_Lrelu')(x)\n","#     # (None, 64, 64, 64)\n","\n","#     x = layers.Conv2D(128, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D2')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='D2_bn')(x)\n","#     x = layers.LeakyReLU(alpha=0.2, name='D2_Lrelu')(x)\n","#     # (None, 32, 32, 128)\n","\n","#     x = layers.Conv2D(256, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D3')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='D3_bn')(x)\n","#     x = layers.LeakyReLU(alpha=0.2, name='D3_Lrelu')(x)\n","#     # (None, 16, 16, 256)\n","\n","#     x = layers.Conv2D(512, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D4')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='D4_bn')(x)\n","#     x = layers.LeakyReLU(alpha=0.2, name='D4_Lrelu')(x)\n","#     # (None, 8, 8, 512)\n","\n","#     x = layers.Conv2D(1024, kernel_size=(4, 4), strides=(1, 1), padding='same', use_bias=False, name='D5')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='D5_bn')(x)\n","#     x = layers.LeakyReLU(alpha=0.2, name='D5_Lrelu')(x)\n","#     # (None, 4, 4, 1024)\n","\n","#     x = layers.Dropout(0.5, name='D_drop1')(x)\n","#     x = layers.Flatten(name='D_flat')(x)\n","#     # (None, 16384)\n","#     x = layers.Dropout(0.5, name='D_drop2')(x)\n","\n","#     x = layers.Dense(1, use_bias=False, name='D_5')(x)\n","#     out = layers.Activation('sigmoid', name='D_final')(x)\n","#     # (None, 1)\n","#     discriminator = models.Model(input_img, out, name='Discriminator')\n","\n","#     discriminator.summary()\n","#     return discriminator\n","\n","# D = build_discriminator((128, 128, 3))"]},{"cell_type":"markdown","metadata":{"id":"JFEivToUBYnv"},"source":["1024 更多dropout應對mode collapse?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"puuS3xL_dtVm"},"outputs":[],"source":["# # 建構鑑別器\n","# def build_discriminator(img_shape):  \n","#     input_img = layers.Input(shape=img_shape, name='D_input')\n","\n","#     x = layers.Conv2D(64, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D_1')(input_img)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='D_bn1')(x)\n","#     x = layers.LeakyReLU(alpha=0.2, name='D_Lrelu1')(x)\n","#     # (None, 32, 32, 64)\n","\n","#     x = layers.Conv2D(128, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D_2')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='D_bn2')(x)\n","#     x = layers.LeakyReLU(alpha=0.2, name='D_Lrelu2')(x)\n","#     # (None, 16, 16, 128)\n","\n","#     x = layers.Conv2D(256, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D_3')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='D_bn3')(x)\n","#     x = layers.LeakyReLU(alpha=0.2, name='D_Lrelu3')(x)\n","#     # (None, 8, 8, 256)\n","\n","#     x = layers.Conv2D(512, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D_4')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='D_bn4')(x)\n","#     x = layers.LeakyReLU(alpha=0.2, name='D_Lrelu4')(x)\n","#     # (None, 4, 4, 512)\n","\n","#     # x = layers.Conv2D(1024, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D_5')(x)\n","#     # x = layers.BatchNormalization(epsilon=0.001, name='D_bn5')(x)\n","#     # x = layers.LeakyReLU(alpha=0.2, name='D_Lrelu5')(x)\n","\n","#     x = layers.Dropout(0.5, name='D_drop1')(x)\n","#     x = layers.Flatten(name='D_flat')(x)\n","#     # 使用Dropout引入隨機性，幫助訓練\n","#     x = layers.Dropout(0.5, name='D_drop2')(x)\n","#     # (None, 8192)\n","\n","#     x = layers.Dense(1, use_bias=False, name='D_5')(x)\n","#     out = layers.Activation('sigmoid', name='D_final')(x)\n","#     # (None, 1)\n","#     discriminator = models.Model(input_img, out, name='Discriminator')\n","\n","#     discriminator.summary()\n","#     return discriminator\n","\n","# D = build_discriminator((128, 128, 3))"]},{"cell_type":"markdown","metadata":{"id":"JWrXyejHBbYq"},"source":["512"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgw3VEppGKhK"},"outputs":[],"source":["# # 建構鑑別器\n","# def build_discriminator(img_shape):  \n","#     input_img = layers.Input(shape=img_shape, name='D_input')\n","\n","#     x = layers.Conv2D(64, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D_1')(input_img)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='D_bn1')(x)\n","#     x = layers.LeakyReLU(alpha=0.2, name='D_Lrelu1')(x)\n","#     # (None, 32, 32, 64)\n","\n","#     x = layers.Conv2D(128, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D_2')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='D_bn2')(x)\n","#     x = layers.LeakyReLU(alpha=0.2, name='D_Lrelu2')(x)\n","#     # (None, 16, 16, 128)\n","\n","#     x = layers.Conv2D(256, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D_3')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='D_bn3')(x)\n","#     x = layers.LeakyReLU(alpha=0.2, name='D_Lrelu3')(x)\n","#     # (None, 8, 8, 256)\n","\n","#     x = layers.Conv2D(512, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False, name='D_4')(x)\n","#     x = layers.BatchNormalization(epsilon=0.001, name='D_bn4')(x)\n","#     x = layers.LeakyReLU(alpha=0.2, name='D_Lrelu4')(x)\n","#     # (None, 4, 4, 512)\n","\n","#     x = layers.Dropout(0.5, name='D_drop1')(x)\n","#     x = layers.Flatten(name='D_flat')(x)\n","#     # 使用Dropout引入隨機性，幫助訓練\n","#     x = layers.Dropout(0.5, name='D_drop2')(x)\n","#     # (None, 8192)\n","\n","#     x = layers.Dense(1, use_bias=False, name='D_5')(x)\n","#     out = layers.Activation('sigmoid', name='D_final')(x)\n","#     # (None, 1)\n","#     discriminator = models.Model(input_img, out, name='Discriminator')\n","\n","#     discriminator.summary()\n","#     return discriminator\n","\n","# # D = build_discriminator((64, 64, 3))"]},{"cell_type":"markdown","metadata":{"id":"lS8sMkz7d95S"},"source":["# **GAN:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NSRC6f6_pev5"},"outputs":[],"source":["# 建構GAN \n","def build_gan(latent_dim, generator, discriminator):\n","    gan_input = keras.Input(shape=(latent_dim,), name='GAN_input')\n","    img = generator(gan_input)\n","    # 凍結Discriminator的權重(只對Generator做訓練)\n","    # discriminator.trainable = False         # Turn ON (可加可不加)\n","    gan_output = discriminator(img)\n","    # discriminator.trainable = True         # Turn OFF\n","    gan = models.Model(gan_input, gan_output, name='GAN')\n","\n","    gan.summary()\n","    return gan\n","\n","# build_gan(128, G, D)\n","# trainable-params only in G and D"]},{"cell_type":"markdown","metadata":{"id":"zMh3R8SgK1Jb"},"source":["# **Initialization:**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3129,"status":"ok","timestamp":1640748423286,"user":{"displayName":"SK","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7--4P44AfAvjw0rUOGVSabQNlfWVEWivQJE9UZA=s64","userId":"06193962436829705248"},"user_tz":-480},"id":"jUUEqALZKqPq","outputId":"08822120-da26-4b41-fc91-b8dcc6a298f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"Generator\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," G_input (InputLayer)        [(None, 128)]             0         \n","                                                                 \n"," G1 (Dense)                  (None, 65536)             8388608   \n","                                                                 \n"," G_reshape (Reshape)         (None, 8, 8, 1024)        0         \n","                                                                 \n"," G1_Lrelu (LeakyReLU)        (None, 8, 8, 1024)        0         \n","                                                                 \n"," G2 (Conv2DTranspose)        (None, 16, 16, 1024)      16777216  \n","                                                                 \n"," G2_bn (BatchNormalization)  (None, 16, 16, 1024)      4096      \n","                                                                 \n"," G2_Lrelu (LeakyReLU)        (None, 16, 16, 1024)      0         \n","                                                                 \n"," G3 (Conv2DTranspose)        (None, 32, 32, 512)       8388608   \n","                                                                 \n"," G3_bn (BatchNormalization)  (None, 32, 32, 512)       2048      \n","                                                                 \n"," G3_Lrelu (LeakyReLU)        (None, 32, 32, 512)       0         \n","                                                                 \n"," G4 (Conv2DTranspose)        (None, 32, 32, 256)       2097152   \n","                                                                 \n"," G4_bn (BatchNormalization)  (None, 32, 32, 256)       1024      \n","                                                                 \n"," G4_Lrelu (LeakyReLU)        (None, 32, 32, 256)       0         \n","                                                                 \n"," G5 (Conv2DTranspose)        (None, 64, 64, 128)       524288    \n","                                                                 \n"," G5_bn (BatchNormalization)  (None, 64, 64, 128)       512       \n","                                                                 \n"," G5_Lrelu (LeakyReLU)        (None, 64, 64, 128)       0         \n","                                                                 \n"," G6 (Conv2DTranspose)        (None, 64, 64, 64)        131072    \n","                                                                 \n"," G6_bn (BatchNormalization)  (None, 64, 64, 64)        256       \n","                                                                 \n"," G6_Lrelu (LeakyReLU)        (None, 64, 64, 64)        0         \n","                                                                 \n"," G7 (Conv2DTranspose)        (None, 128, 128, 3)       3072      \n","                                                                 \n"," G_final (Activation)        (None, 128, 128, 3)       0         \n","                                                                 \n","=================================================================\n","Total params: 36,317,952\n","Trainable params: 36,313,984\n","Non-trainable params: 3,968\n","_________________________________________________________________\n","Model: \"Discriminator\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," D_input (InputLayer)        [(None, 128, 128, 3)]     0         \n","                                                                 \n"," D1 (Conv2D)                 (None, 64, 64, 64)        3072      \n","                                                                 \n"," D1_bn (BatchNormalization)  (None, 64, 64, 64)        256       \n","                                                                 \n"," D1_Lrelu (LeakyReLU)        (None, 64, 64, 64)        0         \n","                                                                 \n"," D1_drop (Dropout)           (None, 64, 64, 64)        0         \n","                                                                 \n"," D2 (Conv2D)                 (None, 32, 32, 128)       131072    \n","                                                                 \n"," D2_bn (BatchNormalization)  (None, 32, 32, 128)       512       \n","                                                                 \n"," D2_Lrelu (LeakyReLU)        (None, 32, 32, 128)       0         \n","                                                                 \n"," D2_drop (Dropout)           (None, 32, 32, 128)       0         \n","                                                                 \n"," D3 (Conv2D)                 (None, 16, 16, 256)       524288    \n","                                                                 \n"," D3_bn (BatchNormalization)  (None, 16, 16, 256)       1024      \n","                                                                 \n"," D3_Lrelu (LeakyReLU)        (None, 16, 16, 256)       0         \n","                                                                 \n"," D3_drop (Dropout)           (None, 16, 16, 256)       0         \n","                                                                 \n"," D4 (Conv2D)                 (None, 8, 8, 512)         2097152   \n","                                                                 \n"," D4_bn (BatchNormalization)  (None, 8, 8, 512)         2048      \n","                                                                 \n"," D4_Lrelu (LeakyReLU)        (None, 8, 8, 512)         0         \n","                                                                 \n"," D4_drop (Dropout)           (None, 8, 8, 512)         0         \n","                                                                 \n"," D5 (Conv2D)                 (None, 8, 8, 1024)        8388608   \n","                                                                 \n"," D5_bn (BatchNormalization)  (None, 8, 8, 1024)        4096      \n","                                                                 \n"," D5_Lrelu (LeakyReLU)        (None, 8, 8, 1024)        0         \n","                                                                 \n"," D5_drop (Dropout)           (None, 8, 8, 1024)        0         \n","                                                                 \n"," D_flat (Flatten)            (None, 65536)             0         \n","                                                                 \n"," D_5 (Dense)                 (None, 1)                 65536     \n","                                                                 \n","=================================================================\n","Total params: 11,217,664\n","Trainable params: 11,213,696\n","Non-trainable params: 3,968\n","_________________________________________________________________\n","Model: \"GAN\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," GAN_input (InputLayer)      [(None, 128)]             0         \n","                                                                 \n"," Generator (Functional)      (None, 128, 128, 3)       36317952  \n","                                                                 \n"," Discriminator (Functional)  (None, 1)                 11217664  \n","                                                                 \n","=================================================================\n","Total params: 47,535,616\n","Trainable params: 47,527,680\n","Non-trainable params: 7,936\n","_________________________________________________________________\n"]}],"source":["# -----------------\n","#    初始化 \n","# -----------------\n","\n","# 儲存Loss＆Accuracy\n","# G_Losses = []                                   ###\n","# D_Losses = []\n","# D_Accuracies = []\n","\n","# 儲存路徑\n","save_dir = \"/content/drive/MyDrive/Colab Notebooks/saves\"\n","# images_dir_name = \"generated_images_1024_noise0.1_lr0.0001_FFHQ\"\n","# model_dir_name = \"model_1024_noise0.1_lr0.0001_FFHQ\"\n","# loss_dir_name = \"Loss&Acc_1024_noise0.1_lr0.0001_FFHQ\"\n","\n","# 設定潛在空間維度\n","latent_dim = 128\n","img_shape = (128, 128, 3)\n","batch_size = 256 # 256 or more (dataset batch記得改)\n","# lr最好跟batch_size一起xN倍\n","epochs = 100\n","# 設定標籤的雜訊\n","noise = 0.05    # *0.05\n","num2generate = 5\n","\n","\n","# 固定的random_vectors，方便觀察epoch間變化\n","fixed_random_vectors = tf.random.normal(shape=(num2generate, latent_dim))\n","# file = open(os.path.join(save_dir, loss_dir_name, \"vectorZ.txt\"),'w')\n","# file.write(str(fixed_random_vectors))\n","# file.close()\n","\n","# model初始化\n","generator = build_generator(latent_dim)                     ###\n","discriminator  = build_discriminator(img_shape)\n","gan = build_gan(latent_dim, generator, discriminator)\n","\n","# 優化器＆學習率設定\n","# 自適應優化器Adam <-> SGD\n","D_optimizer = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)     # 0.00005\n","G_optimizer = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)     # 0.0002\n","# D_optimizer = keras.optimizers.RMSprop(learning_rate=0.0001)     # 0.00005\n","# G_optimizer = keras.optimizers.RMSprop(learning_rate=0.0001)     # 0.0002\n","\n","# 損失函數定義\n","# 默認: from_logits=False輸出為機率[0, 1]與softmax相同\n","# from_logits=True，輸出分布[-inf, inf]\n","loss_function = keras.losses.BinaryCrossentropy(from_logits=True)\n","# BCE: -w(p(x)log x +(1 - p(x))log(1 - x))\n","# 公式寫法的loss function:\n","# D_loss_function = -tf.reduce_mean(tf.log(prob_true) + tf.log(1-prob_fake))\n","# G_loss_function = tf.reduce_mean(tf.log(1-fake))\n","\n","TRAIN_LOGDIR = os.path.join(save_dir, \"WGAN_nor\", 'train_data')\n","file_writer = tf.summary.create_file_writer(TRAIN_LOGDIR)"]},{"cell_type":"markdown","metadata":{"id":"IUB0LxP_hHHT"},"source":["# **Train:**"]},{"cell_type":"markdown","metadata":{"id":"hndieQzhA790"},"source":["\n","\n","```\n","# WGAN Version\n","```\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V0mkhBDB6iVL"},"outputs":[],"source":["from tensorflow.keras import backend as K\n","\n","EPOCHs = 200\n","LAMBDA = 10\n","CURRENT_EPOCH = 1 # Epoch start from\n","SAVE_EVERY_N_EPOCH = 5 # Save checkpoint at every n epoch\n","N_CRITIC = 3 # Train critic(discriminator) n times then train generator 1 time.\n","LR = 1e-4\n","MIN_LR = 0.000001 # Minimum value of learning rate\n","DECAY_FACTOR=1.00004 # learning rate decay factor\n","current_learning_rate = LR\n","trace = True\n","n_critic_count = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10241,"status":"ok","timestamp":1640748567327,"user":{"displayName":"SK","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7--4P44AfAvjw0rUOGVSabQNlfWVEWivQJE9UZA=s64","userId":"06193962436829705248"},"user_tz":-480},"id":"TPZju3_LKTiX","outputId":"94facb13-cf42-4fd3-dc19-fdd4a4b3000c"},"outputs":[{"data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f34f0055790>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# 恢復weights\n","checkpoint_path = os.path.join(save_dir, \"WGAN_nor\", \"checkpoints\")\n","\n","ckpt = tf.train.Checkpoint(generator=generator,\n","                           discriminator=discriminator,\n","                           G_optimizer=G_optimizer,\n","                           D_optimizer=D_optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n","ckpt.restore(ckpt_manager.latest_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15437,"status":"ok","timestamp":1640676308558,"user":{"displayName":"SK","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7--4P44AfAvjw0rUOGVSabQNlfWVEWivQJE9UZA=s64","userId":"06193962436829705248"},"user_tz":-480},"id":"XdvsjjJ54h6y","outputId":"692a67f5-0c19-49f0-a56e-632b01de7bd0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Latest checkpoint of epoch 60 restored!!\n"]}],"source":["checkpoint_path = os.path.join(save_dir, \"WGAN_nor\", \"checkpoints\")\n","\n","ckpt = tf.train.Checkpoint(generator=generator,\n","                           discriminator=discriminator,\n","                           G_optimizer=G_optimizer,\n","                           D_optimizer=D_optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=None)\n","\n","# if a checkpoint exists, restore the latest checkpoint.\n","if ckpt_manager.latest_checkpoint:\n","    ckpt.restore(ckpt_manager.latest_checkpoint)\n","    latest_epoch = int(ckpt_manager.latest_checkpoint.split('-')[1])\n","    CURRENT_EPOCH = latest_epoch * SAVE_EVERY_N_EPOCH\n","    print ('Latest checkpoint of epoch {} restored!!'.format(CURRENT_EPOCH))\n","\n","def generate_and_save_images(model, epoch, test_input, figure_size=(12,6), subplot=(3,6), save=True, is_flatten=False):\n","    '''\n","        Generate images and plot it.\n","    '''\n","    predictions = model.predict(test_input)\n","    if is_flatten:\n","        predictions = predictions.reshape(-1, 128, 128, 3).astype('float32')\n","    fig = plt.figure(figsize=figure_size)\n","    for i in range(predictions.shape[0]):\n","        axs = plt.subplot(subplot[0], subplot[1], i+1)\n","        plt.imshow(predictions[i] * 0.5 + 0.5)\n","        plt.axis('off')\n","    if save:\n","        plt.savefig(os.path.join(save_dir, \"WGAN_nor\", \"generated_imgs\", 'image_at_epoch_{:04d}.png'.format(epoch)))\n","    plt.show()\n","\n","num_examples_to_generate = 18\n","# We will reuse this seed overtime\n","sample_noise = tf.random.normal([num_examples_to_generate, latent_dim])\n","# generate_and_save_images(generator, 0, [sample_noise], figure_size=(12,6), subplot=(3,6), save=False, is_flatten=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1znYb9xLtrWMQS8oAnHfUsvuFGdsZnHVV"},"id":"huYLNskqv8vF","outputId":"c8f7321c-e1f1-4ea0-971c-ab3fe6e0fb24"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["def learning_rate_decay(current_lr, decay_factor=DECAY_FACTOR):\n","    '''\n","        Calculate new learning rate using decay factor\n","    '''\n","    new_lr = max(current_lr / decay_factor, MIN_LR)\n","    return new_lr\n","\n","def set_learning_rate(new_lr):\n","    '''\n","        Set new learning rate to optimizers\n","    '''\n","    K.set_value(D_optimizer.lr, new_lr)\n","    K.set_value(G_optimizer.lr, new_lr)\n","\n","@tf.function\n","def WGAN_GP_train_d_step(real_image, batch_size, step):\n","    '''\n","        One discriminator training step\n","        Reference: https://www.tensorflow.org/tutorials/generative/dcgan\n","    '''\n","    print(\"retrace\")\n","    noise = tf.random.normal([batch_size, latent_dim])\n","    epsilon = tf.random.uniform(shape=[batch_size, 1, 1, 1], minval=0, maxval=1)\n","    ###################################\n","    # Train D\n","    ###################################\n","    with tf.GradientTape(persistent=True) as d_tape:\n","        with tf.GradientTape() as gp_tape:\n","            fake_image = generator([noise], training=True)\n","            fake_image_mixed = epsilon * tf.dtypes.cast(real_image, tf.float32) + ((1 - epsilon) * fake_image)\n","            fake_mixed_pred = discriminator([fake_image_mixed], training=True)\n","            \n","        # Compute gradient penalty                          (原本的LossFunction變成此處的W距離)\n","        grads = gp_tape.gradient(fake_mixed_pred, fake_image_mixed)\n","        grad_norms = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n","        gradient_penalty = tf.reduce_mean(tf.square(grad_norms - 1))\n","        \n","        fake_pred = discriminator([fake_image], training=True)\n","        real_pred = discriminator([real_image], training=True)\n","        \n","        D_loss = tf.reduce_mean(fake_pred) - tf.reduce_mean(real_pred) + LAMBDA * gradient_penalty    # WGAN LossFuncion ！\n","    # Calculate the gradients for discriminator\n","    D_gradients = d_tape.gradient(D_loss,\n","                                            discriminator.trainable_variables)\n","    # Apply the gradients to the optimizer\n","    D_optimizer.apply_gradients(zip(D_gradients,\n","                                                discriminator.trainable_variables))\n","    # Write loss values to tensorboard\n","    if step % 10 == 0:\n","        with file_writer.as_default():\n","            tf.summary.scalar('D_loss', tf.reduce_mean(D_loss), step=step)\n","\n","@tf.function\n","def WGAN_GP_train_g_step(real_image, batch_size, step):\n","    '''\n","        One generator training step\n","        \n","        Reference: https://www.tensorflow.org/tutorials/generative/dcgan\n","    '''\n","    print(\"retrace\")\n","    noise = tf.random.normal([batch_size, latent_dim])\n","    ###################################\n","    # Train G\n","    ###################################\n","    with tf.GradientTape() as g_tape:\n","        fake_image = generator([noise], training=True)\n","        fake_pred = discriminator([fake_image], training=True)\n","        G_loss = -tf.reduce_mean(fake_pred)\n","    # Calculate the gradients for generator\n","    G_gradients = g_tape.gradient(G_loss,\n","                                            generator.trainable_variables)\n","    # Apply the gradients to the optimizer\n","    G_optimizer.apply_gradients(zip(G_gradients,\n","                                                generator.trainable_variables))\n","    # Write loss values to tensorboard\n","    if step % 10 == 0:\n","        with file_writer.as_default():\n","            tf.summary.scalar('G_loss', G_loss, step=step)\n","\n","\n","for epoch in range(CURRENT_EPOCH, EPOCHs + 1):\n","    start = time.time()\n","    print('Start of epoch %d' % (epoch,))\n","    # Using learning rate decay\n","    current_learning_rate = learning_rate_decay(current_learning_rate)\n","    print('current_learning_rate %f' % (current_learning_rate,))\n","    set_learning_rate(current_learning_rate)\n","    \n","    for step, (image) in enumerate(tqdm(dataset)):\n","        current_batch_size = image.shape[0]\n","        # Train critic (discriminator)\n","        WGAN_GP_train_d_step(image, batch_size=tf.constant(current_batch_size, dtype=tf.int64), step=tf.constant(step, dtype=tf.int64))\n","        n_critic_count += 1\n","        if n_critic_count >= N_CRITIC: \n","            # Train generator\n","            WGAN_GP_train_g_step(image, batch_size= tf.constant(current_batch_size, dtype=tf.int64), step=tf.constant(step, dtype=tf.int64))\n","            n_critic_count = 0\n","        \n","        if step % 10 == 0:\n","            print ('.', end='')\n","    \n","    # Using a consistent sample so that the progress of the model is clearly visible.\n","    generate_and_save_images(generator, epoch, [sample_noise], figure_size=(12,6), subplot=(3,6), save=True, is_flatten=False)\n","    \n","    if epoch % SAVE_EVERY_N_EPOCH == 0:\n","        ckpt_save_path = ckpt_manager.save()\n","        print ('Saving checkpoint for epoch {} at {}'.format(epoch,\n","                                                             ckpt_save_path))\n","    \n","    print ('Time taken for epoch {} is {} sec\\n'.format(epoch,\n","                                                      time.time()-start))\n","    \n","# Save at final epoch\n","ckpt_save_path = ckpt_manager.save()\n","print ('Saving checkpoint for epoch {} at {}'.format(EPOCHs,\n","                                                        ckpt_save_path))"]},{"cell_type":"markdown","metadata":{"id":"9P1ih8xpv9xX"},"source":["\n","\n","```\n","# DCGAN Version\n","```\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YgVuPnWkhG5m"},"outputs":[],"source":["# -----------------\n","#  開始訓練網路         @tf.function\n","# -----------------\n","def get_random_vectors(batch_size, latent_dim):\n","  vectors = tf.random.normal(shape=(batch_size, latent_dim))\n","  return vectors\n","\n","def get_labels(batch_size, noise):\n","  # ------- important -------\n","  # 準備label，並加入隨機雜訊\n","  # ---------------------------\n","  real_labels = tf.ones((batch_size, 1))\n","  # np.ones((batch_size, 1))\n","  real_labels += noise * tf.random.uniform(real_labels.shape)   # [0, 1)\n","  # np.random.random(fake_labels.shape)\n","  fake_labels = tf.zeros((batch_size, 1))\n","  fake_labels += noise * tf.random.uniform(fake_labels.shape)\n","  return real_labels, fake_labels\n","\n","def cal_d_loss(D_real, D_fake, noise):\n","  real_labels, fake_labels = get_labels(D_real.shape[0], noise)\n","  real_loss = loss_function(real_labels, D_real)\n","  fake_loss = loss_function(fake_labels, D_fake)\n","  # real_loss＆fake_loss的平均\n","  d_loss = 0.5 * tf.add(real_loss, fake_loss)   # 因.GradientTape()該使用tf而非np (缺少id屬性)\n","  return d_loss\n","\n","def cal_g_loss(gan_out, noise):\n","  real_labels, fake_labels = get_labels(gan_out.shape[0], noise)\n","  g_loss = loss_function(real_labels, gan_out)\n","  return g_loss\n","\n","\n","# ------- important -------\n","#   修飾器@tf.function\n","# py轉譯成tensorflow計算圖(Autograph)\n","#    Eager Execution\n","# ---------------------------\n","@tf.function      # tf.Session + 計算圖\n","def train_network(batch_imgs):\n","    random_latent_vectors = get_random_vectors(batch_size, latent_dim)    # 要不要分別寫進GradientTape()? No.\n","\n","    # ---------------------\n","    #  訓練Discriminator \n","    # ---------------------\n","    with tf.GradientTape() as D_tape:                    # or train_on_batch()\n","\n","      # ------- important -------\n","      # 由於generator中BN層的mean跟std\n","      # True: 只使用當前batch的資料 (training mode)\n","      # False: 使用moving statistics (inference mode)\n","      # ---------------------------\n","      generated_img = generator(random_latent_vectors, training=True)     # 要寫進GradientTape()\n","      # (正向傳播)\n","      D_real = discriminator(batch_imgs, training=True)     # D_real, D_fake -> (0, 1) | sigmoid\n","      D_fake = discriminator(generated_img, training=True)\n","      d_loss = cal_d_loss(D_real, D_fake, noise)\n","      # sigmoid輸出，生成圖片為真的機率(獨立)\n","      d_acc = tf.math.reduce_mean(D_fake)          # 取平均\n","      \n","      # (反向傳播)\n","    grads = D_tape.gradient(d_loss, discriminator.trainable_variables)\n","    d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n","\n","    # ---------------------\n","    #   訓練Generator \n","    # ---------------------\n","    with tf.GradientTape() as G_tape:\n","\n","      # (正向傳播)\n","      # ---------------------\n","      #   training=True\n","      # ---------------------\n","      gan_out = gan(random_latent_vectors, training=True)         # gan_out -> (-1, 1) | tanh      \n","      g_loss = cal_g_loss(gan_out, noise)\n","      \n","      # (反向傳播)\n","    grads = G_tape.gradient(g_loss, generator.trainable_variables)\n","    g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n","    return d_loss, d_acc, g_loss      # Eager Execution .numpy()\n","\n","\n","\n","def train(dataset, epochs):\n","\n","  # 一個完整Epoch (full dataset)\n","  for epoch in range(epochs):\n","    print(\"\")\n","    print(\"==============> Epoch[{}] training:\".format(epoch + 1))                                      # +1\n","    # 計時\n","    start_time = time.time()\n","    # 一次的Iterations (處理一個batch)\n","    for iterations, batch_imgs in enumerate(tqdm(dataset)):     # tqdm\n","\n","      d_loss, d_acc, g_loss = train_network(batch_imgs)\n","      D_Losses.append(d_loss.numpy())         # .numpy()\n","      D_Accuracies.append(d_acc.numpy())\n","      G_Losses.append(g_loss.numpy())\n","      # print loss＆Acc + 進度條\n","      if iterations % 100 == 0: \n","        # print(\" \")\n","        print(\" \\t\\t\\tIteration: [{}] [D_loss: {:.3f}, G_loss: {:.3f}] [Acc: {:.3f}]\"\n","                      .format(iterations, D_Losses[-1], G_Losses[-1], D_Accuracies[-1]))\n","    \n","    # 保存結果\n","    save_images(generator, epoch, fixed_random_vectors, num2generate)\n","    save_models(generator, discriminator, epoch)\n","    save_losses(D_Losses, G_Losses, D_Accuracies)\n","    # 計算這個Epoch所花費的時間\n","    end_time = time.time()\n","    print(\"-----------------------------\")\n","    print(\"Training time: {:6.2f} sec\".format(end_time - start_time))\n","\n","\n","# ---------------------\n","#    保存結果 \n","# ---------------------\n","def save_images(generator, epoch, vectors, num2generate):\n","  # random_vectors = tf.random.normal(shape=(num2generate, latent_dim))  # 改用固定vector\n","\n","  # training設為False\n","  # 讓BN層使用moving statistics來執行圖片生成\n","  results = generator(vectors, training=False)\n","\n","  # 把results轉回rgb格式\n","  results *= 255.\n","  results.numpy()\n","\n","  fig = plt.figure(figsize=(16, 16))\n","  # 保存目前Epoch的生成圖片成果(5 imgs per epoch)\n","  for i in range(num2generate):\n","    imgs = keras.preprocessing.image.array_to_img(results[i])\n","    # imgs.save(os.path.join(save_dir, \"generated_images_1024\", \"generated_img_{epoch}_{i}.png\").format(epoch=(epoch + 1), i=i))\n","    plt.subplot(1, 5, i+1)\n","    plt.imshow(imgs)\n","    plt.axis('off')\n","  plt.savefig(os.path.join(save_dir, images_dir_name, \"images_at_epoch_{:03d}.png\").format(epoch + 1))                    # +1\n","  plt.show()\n","\n","\n","def save_models(generator, discriminator, epoch):\n","  # 保存模型＆權重\n","  generator.save(os.path.join(save_dir, model_dir_name, \"Generator_epoch{}.h5\").format(epoch + 1))                      # +1\n","  discriminator.save(os.path.join(save_dir, model_dir_name, \"Discriminator_epoch{}.h5\").format(epoch + 1))                  # +1\n","\n","\n","def save_losses(D_Losses, G_Losses, D_Accuracies):\n","  # 保存Losses＆Accuracies\n","  file = open(os.path.join(save_dir, loss_dir_name, \"d_loss.txt\"),'w')\n","  file.write(str(D_Losses))\n","  file.close()\n","\n","  file = open(os.path.join(save_dir, loss_dir_name, \"g_loss.txt\"),'w')\n","  file.write(str(G_Losses))\n","  file.close()\n","\n","  file = open(os.path.join(save_dir, loss_dir_name, \"d_acc.txt\"),'w')\n","  file.write(str(D_Accuracies))\n","  file.close()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CXcb2HLwiMhL"},"outputs":[],"source":["train(dataset, epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d-ZCXevll7eC"},"outputs":[],"source":["# ---------------------\n","#  畫出Loss & Acc\n","# ---------------------\n","iterations = range(1, len(D_Losses) + 1)\n","\n","def draw_loss_acc(iteration, loss_dir_name):\n","  plt.figure()\n","  plt.plot(iteration, D_Losses, 'r', label=\"Discriminate Loss\")\n","  plt.plot(iteration, G_Losses, 'b', label=\"Generate Loss\")\n","  plt.title(\"Training Loss\")\n","  plt.xlabel(\"Iteration\")\n","  plt.ylabel(\"Loss\")\n","  plt.legend()\n","  # plt.savefig(os.path.join(save_dir, loss_dir_name, \"Loss.png\"))\n","  plt.show()\n","\n","  plt.figure()\n","  plt.plot(iteration, D_Accuracies, 'g--', label=\"Discriminator Acc\")\n","  plt.title(\"Accuracy of Discriminator\")\n","  plt.xlabel(\"Iteration\")\n","  plt.ylabel(\"Accuracy\")\n","  plt.legend()\n","  # plt.savefig(os.path.join(save_dir, loss_dir_name, \"Accuracy.png\"))\n","  plt.show()\n","\n","\n","# 曲線平滑化 (EMA)\n","def smooth_curve(points, factor=0.8):\n","    smoothed_points = []\n","    for point in points:\n","        if smoothed_points:\n","            previous = smoothed_points[-1]\n","            smoothed_points.append(previous * factor + point * (1 - factor))\n","        else:\n","            smoothed_points.append(point)\n","    return smoothed_points\n","\n","\n","def drawsmooth_loss_acc(iteration, loss_dir_name):\n","  plt.figure()\n","  plt.plot(iteration, smooth_curve(D_Losses), 'r', label=\"Smoothed Discriminate Loss\")\n","  plt.plot(iteration, smooth_curve(G_Losses), 'b', label=\"Smoothed Generate Loss\")\n","  plt.title(\"Smoothed Training Loss\")\n","  plt.xlabel(\"Iteration\")\n","  plt.ylabel(\"Loss\")\n","  plt.legend()\n","  # plt.savefig(os.path.join(save_dir, loss_dir_name, \"Smoothed_Loss.png\"))\n","  plt.show()\n","\n","  plt.figure()\n","  plt.plot(iteration, smooth_curve(D_Accuracies), 'g--', label=\"Discriminator Acc\")\n","  plt.title(\"Smoothed Accuracy of Discriminator\")\n","  plt.xlabel(\"Iteration\")\n","  plt.ylabel(\"Accuracy\")\n","  plt.legend()\n","  # plt.savefig(os.path.join(save_dir, loss_dir_name, \"Smoothed_Accuracy.png\"))\n","  plt.show()\n","\n","\n","save_dir = \"/content/drive/MyDrive/Colab Notebooks/saves\"\n","# loss_dir_name = \"Loss&Acc_1024_noise0.1_lr0.0001_FFHQ\"\n","draw_loss_acc(iterations, loss_dir_name)\n","drawsmooth_loss_acc(iterations, loss_dir_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cAYVgN-yiCNn"},"outputs":[],"source":["# GIF\n","import glob\n","import imageio\n","\n","images_dir_name = \"generated_imgs\"\n","\n","anim_file = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/saves\", \"WGAN_nor\",images_dir_name, \"my_dcgan.gif\")\n","\n","with imageio.get_writer(anim_file, mode='I') as writer:\n","  filenames = glob.glob(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/saves\", \"WGAN_nor\",images_dir_name, 'image*.png'))\n","  filenames = sorted(filenames)\n","  for filename in filenames:\n","    image = imageio.imread(filename)\n","    writer.append_data(image)\n","  image = imageio.imread(filename)\n","  writer.append_data(image)\n"]},{"cell_type":"markdown","metadata":{"id":"6HiOObSDXbye"},"source":["# **意外中斷恢復訓練:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HvOyZ8CoXoUr"},"outputs":[],"source":["def load_models(epoch, model_dir_name):\n","  generator = keras.models.load_model(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/saves\", model_dir_name, \"Generator_epoch{}.h5\")\n","                                                                    .format(epoch))\n","  generator.summary()\n","  discriminator = keras.models.load_model(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/saves\", model_dir_name, \"Discriminator_epoch{}.h5\")\n","                                                                      .format(epoch))\n","  discriminator.summary()\n","  return generator, discriminator\n","\n","def load_losses(loss_dir_name):\n","  with open(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/saves\", loss_dir_name, \"g_loss.txt\"), 'r') as files:\n","    G_Losses = files.read()\n","  G_Losses = eval(G_Losses)\n","  print(\"g_loss: length={} type={}\".format(len(G_Losses), type(G_Losses)))\n","  \n","  with open(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/saves\", loss_dir_name, \"d_loss.txt\"), 'r') as files:\n","    D_Losses = files.read()\n","  D_Losses = eval(D_Losses)\n","  print(\"d_loss: length={} type={}\".format(len(D_Losses), type(D_Losses)))\n","\n","  with open(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/saves\", loss_dir_name, \"d_acc.txt\"), 'r') as files:\n","    D_Accuracies = files.read()\n","  D_Accuracies = eval(D_Accuracies)\n","  print(\"d_acc: length={} type={}\".format(len(D_Accuracies), type(D_Accuracies)))\n","  return G_Losses, D_Losses, D_Accuracies\n","\n","\n","model_dir_name = \"model_1024_noise0.1_lr0.0001_FFHQ\"\n","loss_dir_name = \"Loss&Acc_1024_noise0.1_lr0.0001_FFHQ\"\n","epoch = 23\n","# generator, discriminator = load_models(epoch, model_dir_name)\n","G_Losses, D_Losses, D_Accuracies = load_losses(loss_dir_name)"]},{"cell_type":"markdown","metadata":{"id":"kAmCuf0YsrKm"},"source":["# **載入已訓練模型生成圖片:**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1j71ucHeDkEidUqS2U8EuQrwTuCNoPstC"},"id":"ux8TVxvCqT-w","outputId":"43593ff9-462f-42e8-91ff-6e4541b908ab"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["def get_models(epoch, model_dir_name):\n","  generator = keras.models.load_model(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/saves\", model_dir_name, \"Generator_epoch{}.h5\")\n","                                                                    .format(epoch))\n","  generator.summary()\n","  discriminator = keras.models.load_model(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/saves\", model_dir_name, \"Discriminator_epoch{}.h5\")\n","                                                                      .format(epoch))\n","  discriminator.summary()\n","  return generator, discriminator\n","\n","def generating(num2generate, latent_dim, epoch, images_dir_name):\n","  random_vectors = tf.random.normal(shape=(num2generate, latent_dim))\n","  results = generator(random_vectors, training=False)\n","  results *= 255.\n","  results.numpy()\n","\n","  fig = plt.figure(figsize=(50, 50))\n","  for i in range(num2generate):\n","    imgs = keras.preprocessing.image.array_to_img(results[i])\n","    # imgs.save(\"generated_img_{i}.png\".format(epoch=epoch, i=i))\n","    plt.subplot(10, 10, i+1)\n","    plt.imshow(imgs)\n","    plt.axis('off')\n","  plt.savefig(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/saves\", images_dir_name, \"images_at_epoch_({}).png\").format(epoch))\n","  plt.savefig(\"1.png\")\n","  plt.show()\n","\n","\n","\n","model_dir_name = \"WGAN_nor/generated_imgs\"\n","images_dir_name = \"WGAN_nor/generated_imgs\"\n","epoch = 100\n","# generator, discriminator = get_models(epoch, model_dir_name)\n","generating(100, 128, epoch, images_dir_name)"]},{"cell_type":"markdown","metadata":{"id":"z0pY5QSGOXVJ"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","---\n","# **test**\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","---\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"MY_DCGAN.ipynb","provenance":[],"mount_file_id":"1JJvvl-6rYEf9way-aIHttGSDO1PmGU7R","authorship_tag":"ABX9TyNVTIgLHSgZJh+g5AumcUpG"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}